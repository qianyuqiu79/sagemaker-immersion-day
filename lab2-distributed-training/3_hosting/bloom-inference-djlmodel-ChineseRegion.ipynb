{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81ce8a34-40db-414f-91ec-7a35c146174d",
   "metadata": {},
   "source": [
    "# bloom inference\n",
    "\n",
    "For Chinese regions\n",
    "\n",
    "https://huggingface.co/bigscience/bloom-7b1  7b , ~14GB size\n",
    "\n",
    "https://huggingface.co/bigscience/bloom 176B , bigscience/bloom ~360GB size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254694d-3602-443a-b3c5-370a09d29cd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#upgrade sdk library\n",
    "!pip install -qU sagemaker -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install -qU boto3 -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install -qU botocore -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ed1be-985e-445c-9eee-e8fa1aecd71d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sagemaker environment setting\n",
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "import shutil\n",
    "import sagemaker.huggingface\n",
    "from sagemaker.djl_inference.model import DJLModel,DeepSpeedModel,HuggingFaceAccelerateModel,DJLPredictor\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sagemaker_session is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sagemaker_session = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {bucket}\")\n",
    "print(f\"sagemaker session region: {region}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02cf8376-9be4-43a3-b6e6-a7b24b61087b",
   "metadata": {},
   "source": [
    "## Download model files from huggingface hub, then upload to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30632eed-4dd0-4a46-9663-57eb171ae783",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qU huggingface_hub -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32619875-f1e0-429f-a68c-f20ea4215983",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "# - This will download the model into the ./model directory where ever the jupyter file is running\n",
    "local_model_path = Path(\"tmp\")\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "#model_name = \"bigscience/bloom\" 360GB \n",
    "model_name = \"bigscience/bloom-7b1\"\n",
    "#model_name = \"microsoft/bloom-deepspeed-inference-int8\"\n",
    "#commit_hash = \"aa00a6626f6484a2eef68e06d1e089e4e32aa571\"\n",
    "\n",
    "# - Leverage the snapshot library to donload the model since the model is stored in repository using LFS\n",
    "snapshot_download(repo_id=model_name, cache_dir=local_model_path, allow_patterns=[\"*.json\",\"*.bin\",\"*.md\",\"*.pt\"], ignore_patterns=[\"*.safetensors\",\"*.msgpack\",\"*.h5\"])\n",
    "\n",
    "# - Upload to S3 using AWS CLI\n",
    "s3_model_prefix = model_name  # folder where model checkpoint will go\n",
    "model_snapshot_path = list(local_model_path.glob(\"**/snapshots/*\"))[0]\n",
    "\n",
    "print(f'model_snapshot_path:{model_snapshot_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb33a2f3-4922-48a5-a736-2bf381f96d5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model_snapshot_path=\"tmp/models--microsoft--bloom-deepspeed-inference-int8/snapshots/aa00a6626f6484a2eef68e06d1e089e4e32aa571\"\n",
    "#s3_model_prefix = \"microsoft/bloom-deepspeed-inference-int8\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0542a0-2999-4e38-b362-f96f4ce414d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!chmod 777 s5cmd\n",
    "\n",
    "!./s5cmd sync $model_snapshot_path/ s3://$bucket/$s3_model_prefix/\n",
    "!aws s3 ls s3://$bucket/$s3_model_prefix/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a41b8a-eb98-4f6c-a774-a2af26e3ca05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = f\"s3://{bucket}/{s3_model_prefix}/\"\n",
    "print(f\"model_id:{model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e7873e-c051-4432-b94b-515314bfcda0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_dir='source_dir'\n",
    "entry_point = 'entry_point.py'\n",
    "\n",
    "if os.path.exists(source_dir):\n",
    "    shutil.rmtree(source_dir)\n",
    "!mkdir $source_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6386a49-c18e-427b-908a-6c9442b370dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LMI + Create a model using the DeepSpeed backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2736d262-65c9-4a7f-b57c-ae16a001b08c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile $source_dir/requirements.txt\n",
    "# Start writing content here (remove this file if not neeed)\n",
    "-i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "transformers==4.22.2\n",
    "sentencepiece\n",
    "protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847a5ac0-7cb4-432b-b4c6-83bdbf7d621b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# configure tensor_parallel_degree according gpu\n",
    "instance_type = \"ml.g4dn.2xlarge\"\n",
    "if instance_type in [\"ml.p4d.24xlarge\",\"ml.p4de.24xlarge\",\"ml.p3.16xlarge\",\"ml.p3dn.24xlarge\",\"ml.g5.48xlarge\"]: # 8 GPU\n",
    "    tensor_parallel_degree = 8\n",
    "elif instance_type in [\"ml.p3.8xlarge\",\"ml.g5.24xlarge\",\"ml.g5.12xlarge\",\"ml.g4dn.12xlarge\"]: # 4 GPU\n",
    "    tensor_parallel_degree = 4\n",
    "elif instance_type in []: # 2 GPU\n",
    "    tensor_parallel_degree = 2\n",
    "elif instance_type in [\"ml.p3.2xlarge\",\"ml.g5.xlarge\",\"ml.g5.2xlarge\",\"ml.g5.4xlarge\",\"ml.g5.8xlarge\",\"ml.g5.16xlarge\",\"ml.g4dn.xlarge\",\"ml.g4dn.2xlarge\",\"ml.g4dn.4xlarge\",\"ml.g4dn.8xlarge\",\"ml.g4dn.16xlarge\"]: # 1 GPU\n",
    "    tensor_parallel_degree = 1\n",
    "else:\n",
    "    tensor_parallel_degree = 0\n",
    "    \n",
    "print(f\"instance_type:{instance_type} ; tensor_parallel_degree : {tensor_parallel_degree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca797b94-a274-435c-b6cb-efcfaaedd053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LMI + Create a model using the DeepSpeed backend    \n",
    "deepspeed_model = DeepSpeedModel(\n",
    "    model_id, # This can also be a HuggingFace Hub model id\n",
    "    role,\n",
    "    dtype=\"fp16\",\n",
    "    task=\"text-generation\",\n",
    "    tensor_parallel_degree=tensor_parallel_degree, # number of gpus to partition the model across using tensor parallelism\n",
    "    #entry_point = entry_point,\n",
    "    source_dir = source_dir\n",
    ")\n",
    "# Deploy the model to an Amazon SageMaker Endpoint and get a Predictor\n",
    "deepspeed_predictor = deepspeed_model.deploy(instance_type=instance_type,\n",
    "                                         initial_instance_count=1,\n",
    "                                         #model_data_download_timeout=10*60,\n",
    "                                         #container_startup_health_check_timeout=15*60\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0146ed-0100-4ecd-8cb3-477d950dbba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#predict\n",
    "print(deepspeed_predictor.predict(\n",
    "    { \n",
    "        \"inputs\" : \"Large model inference is\", \n",
    "        \"parameters\": { \"max_length\": 50 },\n",
    "    }\n",
    "))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd193675-b85f-4d58-930b-a0d7971c25c2",
   "metadata": {},
   "source": [
    "## LMI + Create a model using the HuggingFace Accelerate backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8a10e5-680a-45b9-a5ec-786a07cccd7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile $source_dir/requirements.txt\n",
    "# Start writing content here (remove this file if not neeed)\n",
    "-i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "transformers==4.22.2\n",
    "sentencepiece\n",
    "protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fc1915-84d6-4ded-82d5-2b70ca20ca6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# LMI + Create a model using the HuggingFace Accelerate backend\n",
    "\n",
    "hf_accelerate_model = HuggingFaceAccelerateModel(\n",
    "    model_id, # This can also be a HuggingFace Hub model id\n",
    "    role,\n",
    "    dtype=\"fp16\", #dtype\n",
    "    task=\"text-generation\",\n",
    "    number_of_partitions=tensor_parallel_degree, # number of gpus to partition the model across\n",
    "    #entry_point = entry_point,\n",
    "    source_dir = source_dir\n",
    ")\n",
    "\n",
    "\n",
    "hf_accelerate_predictor = hf_accelerate_model.deploy(instance_type=instance_type,\n",
    "                                                     initial_instance_count=1,\n",
    "                                                     # model_data_download_timeout=5*60,\n",
    "                                                     #container_startup_health_check_timeout=10*60\n",
    "                                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff7d3e-ec2d-4b81-ab7c-73374344606f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#predict\n",
    "print(hf_accelerate_predictor.predict(\n",
    "    { \n",
    "        \"inputs\" : \"Large model inference is\", \n",
    "        \"parameters\": { \"max_length\": 50 },\n",
    "    }\n",
    "))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40ffdb84-8f17-43ca-b5fe-348d01a27de8",
   "metadata": {},
   "source": [
    "## only for re-invoke already-created endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab252a6b-e7a4-4253-8281-85deff803b2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#only for re-invoke already-created endpoint\n",
    "\n",
    "from sagemaker import Model, image_uris, serializers, deserializers\n",
    "endpoint_name = \"djl-inference-2023-05-08-07-30-32-434\"\n",
    "predictor = DJLPredictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=serializers.JSONSerializer(),\n",
    "    deserializer=deserializers.JSONDeserializer(),\n",
    ")\n",
    "#predict\n",
    "print(predictor.predict(\n",
    "    { \n",
    "        \"inputs\" : \"Large model inference is\", \n",
    "        \"parameters\": { \"max_length\": 50 },\n",
    "    }\n",
    "))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0176edd-0a56-4756-ba05-698db2464447",
   "metadata": {},
   "source": [
    "## clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85351ea4-e0e0-4194-b07c-605f243abd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"\"\n",
    "model_name = \"\"\n",
    "#sagemaker_session.delete_endpoint(endpoint_name)\n",
    "#sagemaker_session.delete_endpoint_config(endpoint_name)\n",
    "#sagemaker_session.delete_model(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe46e6f-f1d8-47b7-a25b-b1e369337dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.c5.9xlarge",
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
